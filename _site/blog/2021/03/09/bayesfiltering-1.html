<!DOCTYPE html>
<!--[if lt IE 7 ]><html class="ie ie6" lang="en"> <![endif]-->
<!--[if IE 7 ]><html class="ie ie7" lang="en"> <![endif]-->
<!--[if IE 8 ]><html class="ie ie8" lang="en"> <![endif]-->
<!--[if (gte IE 9)|!(IE)]><!--><html lang="en"> <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Giseop Kim - Bayesian Filtering 이야기 (1편): posterior 의 mean, covariance 구하기 (수식 유도)</title>
  <meta name="author" content="Giseop Kim" />
  <meta name="description" content="The blog of Giseop Kim" />
  <link rel="canonical" href="http://localhost:4000/blog/2021/03/09/bayesfiltering-1.html" />

  <link href="//fonts.googleapis.com/css?family=Open+Sans:600,800" rel="stylesheet" type="text/css">
  <link rel="shortcut icon" href="/favicon_logo.png" type="image/vnd.microsoft.icon">
  <link rel="alternate" type="application/atom+xml" title="Giseop Kim" href="http://localhost:4000/atom.xml" />

  <!-- see the how-to-use of academicon here http://jpswalsh.github.io/academicons/ -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="/assets/css/all.css">
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">

  <!-- 
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$', '$$'] ],
        processEscapes: true,
      }
    });
    MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
    MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
    </script>
    <script type="text/javascript" async
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
   -->

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        processEscapes: true
      }
    });
    </script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

    
</head>
<body>
  <div class="container">
    <div class="four columns sidebar">
      <nav>
  <!-- <h1>Hi,</h1> -->

  <!-- <hr class="solid" style="margin-top:+20px"> -->
  
  <p style="margin-top:-7px"> </p>

  <a href="/">
    
    <img src="/logo.png" id="logo" alt="Blog logo" width="150"/>
    
  </a>

  <h2 style="margin-top:-15px"> 
    <!-- <a href="/" style="font-weight:bold" target="_blank">Giseop Kim</a> <a href="/"> blog </a>  -->
    <a href="/" style="font-weight:bold">Giseop Kim</a> <a href="/"> blog </a> 
  </h2>

  <hr class="solid" style="margin-top:+15px">

  <p style="margin-top:-15px">
  </p>

  <div id="bio">
    <br><br> 
    <p style="margin-top:-65px">
      <!-- <span style="vertical-align:150%"> </span><br> -->
      <center> Ph.D. candidate at <a href="https://irap.kaist.ac.kr/" target="_blank"> KAIST </a> </center>
      <!-- <span style="vertical-align:-15%"> </span><br> -->
      <center style="font-size:0.95em"> SLAM researcher/engineer </center>
      <center style="font-size:0.95em"> Spatial AI Enthusiast </center>
    </p>  
    <p>
      <!-- <span style="vertical-align:-15%"> </span><br> -->
      <center style = "margin-top:-10px; font-size:0.9em; letter-spacing:1.3px;"> paulgkim@kaist.ac.kr </center> 
      <!-- font-family:Serif; -->
    </p>
    <!-- <p>
      Edit me in <code>_includes/sidebar.html</code>
    </p> -->
  </div>

  <p style="margin-top:-5px"> </p>
  <div id="social">
    <!-- <center> My channels </center> -->
<center>
<div id="stalker">

  <a title="home" href="/">
    <i class="fa fa-home"></i> 
  </a>

  <a title="notion cv blog" href="http://bit.ly/gk_profile" target="_blank">
    <i class="fa fa-user"></i> 
  </a>

  <a title="CV" href="https://github.com/gisbi-kim/cv-gskim" target="_blank">
    <i class="ai ai-cv"></i> 
  </a>
  
  <a title=" on Scholar" href="https://scholar.google.com/citations?user=9mKOLX8AAAAJ&hl=en" target="_blank">
    <i class="ai ai-google-scholar"></i> 
    <!-- google -->
  </a>

  
  <a title="gisbi-kim on Github" href="https://github.com/gisbi-kim" target="_blank">
    <i class="fa fa-github-square"></i> 
  </a>
  

  <a title=" on Youtube" href="https://www.youtube.com/channel/UCrmVMJ3KEFbDD9EtnAmDT6g" target="_blank">
    <i class="fa fa-youtube-square"></i> 
  </a>

  

  

  

  

  <!-- 
  <a title="GiseopK on Twitter" href="https://twitter.com/GiseopK" target="_blank">
    <i class="fa fa-twitter-square"></i>
  </a>
   -->

  

  

  

  

  

  
</div>
</center>
  </div>

</nav>

    </div>

    <div class="eleven columns content">

      <div class="header">
        <p style="margin-top:-38px"> </p>

<!-- <div class="disclaimer" style="margin-top:+5px"> -->

  <!-- <center style="margin-bottom:-15px">  <a href="/"> Giseop Kim blog </a> </center> -->
  <!-- <a title="home" style="float:right" href="/latestnews/">
    Latest News -->
    <!-- <i class="fa fa-home"></i>  -->
  <!-- </a> -->
  
  <!-- <span>
    <a title="home" style="float:left" href="/aboutme/"> -->
      <!-- About Me  -->
      <!-- <i class="fa fa-home"></i>  -->
    <!-- </a>  
  </span>   -->

  <!-- <span>
    <a title="home" style="float:right" href="/aboutme/"> 
      About Me  -->
      <!-- <i class="fa fa-home"></i>  -->
    <!-- </a>  
  </span>   -->

<!-- </div> -->
      </div> 
      <br>
      <hr class="solid" style="margin-top:+10px">
      <p style="margin-bottom:-20px">
      
      <p class="meta">
  
    [Filtering-based SLAM] ― March 09, 2021   
   
  
  <a href="/">
    <i class="home fa fa-home"></i>
  </a>
</p>

<h1 class="title">Bayesian Filtering 이야기 (1편): posterior 의 mean, covariance 구하기 (수식 유도)</h1>
<hr class="solidlight" style="margin-top:+20px">

<div id="post">
  <h1 id="개요">개요</h1>

<p>SLAM은 filtering-based 와 optimization-based 로 편의상 나눌 수 있다.<br />
(물론 두 방법이 robot 의 state 를 추정하는데 상보적으로 동시에 쓰일수도 있다.)</p>

<p><span style="color:gray"> [Factor graph-based SLAM] </span> 에서는<br />
optimization-based 기반의 SLAM에 대해서 소개하고 있다.</p>

<p>한편,  <span style="color:gray"> [Filtering-based SLAM] </span> 시리즈에서는<br />
filtering-based SLAM 에 대해서 소개하려고 하는데,<br />
이 포스트 (와 몇 편 더) 에서는, 그전에 먼저<br />
filtering-based SLAM의 근간이 되는 Bayesian analysis 자체에 대해 소개하려고 한다.<br />
mathmatical machinary 랄까, 기본을 알면 SLAM은 오히려 쉬울 것이다. 
<br /></p>

<hr />
<h1 id="bayesisan-analysis-란">Bayesisan Analysis 란?</h1>

<h2 id="intro">Intro</h2>

<p>Bayesisan Analysis 이 무엇인지 설명하기 전에,<br />
Bayesisan Analysis 이 왜 필요한지, 예시 상황으로부터 시작해보자.</p>

<p>우리는 어떤 한 시점에서 로봇의 위치를 알고싶다.<br />
이 경우 위치를 $\textbf{x}_{i} = (x, y)$ 의 두 값으로 표현할 수 있다. (heading 은 편의상 생략)</p>

<ul>
  <li>상황 1:
    <p style="margin-top:-15px"> </p>
    <p>로봇은 위치를 추정하기 위해서 GPS를 사용했다. <br />
GPS는 로봇의 위치가 $(1,2)$ 라고 알려주었다 (measurement, $h_1(\cdot)$).</p>

    <p>그래서 로봇은 자기의 위치를 $(1,2)$ 이라고 생각하고 여러 미션을 수행하려고 한다.</p>

    <p>근데 GPS는 로봇의 위치가 다시 $(1.5, 3)$ 라고 알려주었다 (measurement 2, $h_2(\cdot)$).<br />
그래서 로봇은 자기의 위치를 다시 $(1.5, 3)$ 으로 바꿨다.<br />
근데 GPS는 로봇의 위치가 다시 $(2.5, 1)$ 라고 알려주었다 (measurement 3, $h_3(\cdot)$).<br />
그래서 로봇은 자기의 위치를 다시 $(2.5, 1)$ 으로 바꿨다.</p>

    <p>… 무한반복 …<br />
로봇은 확신없이 자기 위치를 결국 추정하지 못하고 결국 세월이 다갔다 …</p>

    <p>이렇게, 매번 개별 measurement만의 가능도 (likelihood) 를 최대화 해주는 방식으로<br />
위치를 추정하는 게 좋은 방법일까?<br />
이러면 그때그때 들어오는 measurement 에 biased 된 예측이 내려질 것이다<sup id="fnref:likelihood" role="doc-noteref"><a href="#fn:likelihood" class="footnote">1</a></sup>.</p>

  </li>
</ul>

<p id="situ2"> </p>
<ul>
  <li>상황 2:
    <p style="margin-top:-15px"> </p>
    <p>상황1과 똑같이, 로봇은 위치를 추정하기 위해서 GPS를 사용했다. <br />
GPS는 로봇의 위치가 $(1,2)$ 라고 알려주었다 (measurement, $h_1(\cdot)$).</p>

    <p>근데 이 로봇은 자기의 현재 위치가 $(0.5, 2)$ 라고 믿고 있는 상태이다 (prior).<br />
이 값은 현재 시점에서 측정 (measurement) 한 것은 아니지만 로봇이 알고있는 어떤 믿음이다.</p>

    <p>로봇은 이 경우에도 상황1에서와 같이 현재 측정된 정보만을 최대화 하도록<br />
자기의 위치를 추정해야할까?<br />
흠 근데 그건 좀 unreasonable 해 보인다.<br />
prior 와 measurement 두 정보를 모두 고려하는 게 좋을 것 같다.</p>

    <p>근데 만약 prior 와 measurement 두 정보를 모두 고려한다 하더라도,<br />
수학적으로 어떻게 융합하여야 하는가?</p>
  </li>
</ul>

<p>이에 대답하기 전에 먼저 아주 간단한 수학을 recap하고 넘어가자.</p>

<h2 id="bayes-rule">Bayes Rule</h2>

<p>Bayesisan Analysis 의 기본 틀은 Bayes Rule 이다.<br />
대학교 확률과 통계 수업을 들으면<br />
거의 첫주에 배우는 아주 기초적이고, 제일 먼저 나오는 내용이라고 할 수 있다.<br />
다들 알다시피 Bayes Rule 을 쓰면 다음과 같다.</p>

\[\begin{align*}
  p(A \ | \ B) &amp;\propto p(A) \cdot p( B \  | \ A) \\ 
\end{align*}\]

<p>그런데 robotics (or 여타 estimation 문제) 에서 실제로 중요한 것은<br />
위에서 $A$와 $B$의 위치가 바뀌는게 베이즈어쩌구구나~ 음~ 외웠어~ 가 아니라</p>

<p>$A$와 $B$ 자리에 들어가는 것이,<br />
<u>실 세계에서 어떤 물리적 의미를 지니는지</u>를 이해하는 것이 중요하다.</p>

<h2 id="bayesisan-analysis-란-1">Bayesisan Analysis 란?</h2>

<p>Bayesian analysis 는 우리가 알고싶은 parameter (들, variables as vector)의<br />
posterior probability 를 maximize 하는<br />
optimal parameter (그래서 maximum a posteriori, MAP) 를 찾는 방법을 말한다.</p>

<p>먼 말인지 차근차근 살펴보자.</p>

<p>우리는 시스템의 어떤 상태에 대해 알고 싶다<br />
(예: 로봇의 위치, 로봇의 calibration parameter 등 어떤 것이든.)</p>

<p>이것을 $\textbf{x}$ 라고 해보자 (state).</p>

<p>우리는 $\textbf{x}$ 를 예측하기 위한 단서들을 가지고 있다 (measurement).<br />
로봇은 센서를 가지고 있기 때문에 다양한 측정을 할 수 있다.<br />
(예: laser 센서로 알려진 랜드마크까지의 거리를 재기, GPS로 위치를 바로 얻기 등)</p>

<p>robotics 에서 measurement 는 문자로 적을 때는 $\textbf{z}$ 로 많이 적는 편이다.</p>

<p>따라서 우리가 관심있는 SLAM (i.e., state estimation) 이란 문제는,</p>

<p>로봇이 가진 센서를 이용해서 얻은 다양한 측정값이 주어졌을 때 (given),<br />
$\textbf{x}$ 를 추론하는 과정 이 된다 (inference).</p>

<p>이를 수학적으로 표현하면 $p ( \textbf{x} \ | \ \textbf{z}_{1:k} )$ 로 쓸 수 있다.</p>

<p>중간의 $|$ 는 “given” 으로 읽는다.<br />
$\textbf{z}$의 subscript 인 $1:k$는 총 k개의 measurement 가 있다고 가정하자, 라는 의미인데 간단히 생략되기도 한다.<br />
문맥에 따라 때로는 time $= 1$ 부터 $t$ 까지의 측정값, 처럼 time 에 걸쳐 얻은 measurement 로 이해되기도 한다.</p>

<p>따라서 SLAM (state estimation)이란 무엇인가?<br />
수학적으로:<br />
$\textbf{z}$가 given 일 때<br />
$\textbf{x}$의 확률이 최대가 되는 $\textbf{x}$ 값을 구하는 것이다.</p>

<p>그런데, Practically, 공학적으로는 어지간하면<br />
우리는 관심있는 random variable 들 ($\textbf{x}$ 등)이<br />
모두 Gaussian 이라고 가정한다.<br />
Gaussian 분포는 여러가지 유용한 성질이 있기 때문이다 (후술함). $+\alpha$<sup id="fnref:alpha" role="doc-noteref"><a href="#fn:alpha" class="footnote">2</a></sup></p>

<p>암튼 우리가 최대화하려는 이 확률 $p ( \textbf{x} \ | \ \textbf{z}_{1:k} )$ 은<br />
measurement 가 측정이 완료되어서, 주어져야 계산할 수 있기 때문에<br />
사후확률 (posterior) 이라고 부른다.</p>

<p>그런데 이 posterior는 Bayes rule 에 의해,<br />
다음과 같이 두개의 텀으로 분리가 되고, 각각을 prior 와 likelihood 라고 부른다.</p>

\[\begin{align*}
  p(\textbf{x} \ | \ \textbf{z}_{1:k}) &amp;\propto p(\textbf{x}) \cdot p(\textbf{z}_{1:k} \ | \ \textbf{x}) \\ 
  \text{posterior} &amp;\propto \text{posterior} \cdot \text{likelihood}
\end{align*}\]

<p>여기서 보통 분모는 normalization 용도 (확률의 정의를 지켜주기 위해서 sum 을 1로 만들어주는 역할)로 생각되기 때문에, 통상적으로 practically 생략하는 편이 많다. 어짜피 우리가 관심이 있는 것은 최대확률값이 아니라, 최대확률이 될 때의 $\textbf{x}$값이기 때문이다 (상수의 곱에 무관하다).</p>

<p>이 때 보통 우리는 prior 와 likelihood 가 둘 다 Gaussian 을 따른다고 가정한다.<br />
그러면 Gaussian 의 좋은(!) 성질 덕분에 posterior 도 Gaussian이 된다.</p>

<p>여기서 그럼 다시 물어야 할 것이, posterior가 Gaussian인 것이 (state estimation 관점에서) 왜 중요할까?</p>

<ul>
  <li>일단 Gaussian은 optimal argmax 값을 얻기가 편하다 (median이 mean 과 같음).</li>
  <li>그리고 Gaussian인 경우, 자연스럽게 recursive 한 estimation 이 가능해진다.<br />
이게 뭔말이냐면, 현재 턴의 posterior 가 다음턴의 prior 로 쓰인다고 생각해보자.<br />
앞서, 우리는 prior 가 Gaussian이라고 가정했었다. 그럼 posterior 도 Gaussian이 되고, 다음턴의 prior 도 다시 Gaussian이 되고, 그 턴의 posterior 도 다시 Gaussian이 되고, … 무한 반복.<sup id="fnref:conju" role="doc-noteref"><a href="#fn:conju" class="footnote">3</a></sup></li>
</ul>

<p>즉, 현재 시점에서 얻은 사전 정보를 다음턴에 자연스럽게 활용할 수 있다.</p>
<ul>
  <li>
    <p>심지어 가우시안의 유용한 성질들 덕분에 그 recursive update 조차도 closed form 으로 딱 떨어진다 (곧 증명해본다).</p>
  </li>
  <li>
    <p>또한, Gaussian은 mean (optimal) 과 더불어 covariance (uncertainty) 도 얻을 수 있다.<br />
(robotics 는 거의 uncertainty 에 관한 학문이라고 할 수 있을만큼 이 uncertainty 는 다양하게 쓰이고 중요하다)<br />
예를 들어 앞서 본 <a href="#situ2">예시상황2</a> 에서 prior 와 likelihood 를 어떻게 융합해야하는지에 관한 문제가 있었다. 이 비율의 balancing 이 prior 와 likelihood 각각의 uncertainty 들에 의해 조절된다 (곧 증명해본다)!</p>
  </li>
</ul>

<h2 id="암튼-정리해보자면">암튼 정리해보자면</h2>
<p>우리가 state estimation 에서 Bayesian filtering 이라고 부르는 것은 다음과 같은 상황을 의미한다.</p>
<ul>
  <li>로봇은 자신의 위치 (and 속도, 주변 맵 포인트들의 위치, 자신의 내부 상태 등 다양한 어떤 값들) $\textbf{x}$ 를 알고 싶다.</li>
  <li>로봇은 센서측정데이터 (measurement) $\textbf{z}_{1:k}$ 를 가지고 있다.</li>
  <li>우리는 $ p(\textbf{x} \ | \ \textbf{z}_{1:k}) $ 를 최대화 하고 싶다.<br />
== 우리는 posterior probability 의 mean (== 확률을 최대로 하는 $\textbf{x}$) 과 covariance 를 알고 싶다.</li>
  <li>우리는 posterior 를 직접 최대화하는 것이 아니라, 대신 우회적으로 prior 와 likelihood 의 곱을 최대화 한다.</li>
  <li>prior 와 likelihood의 분포로 Gaussian 을 사용한다.</li>
  <li>covariance는 pior 와 likelihood 를 융합할 때 기여도를 고려하는 역할을 한다.<sup id="fnref:cov" role="doc-noteref"><a href="#fn:cov" class="footnote">4</a></sup></li>
</ul>

<hr />
<h1 id="posterior-의-mean-covariance-구하기">Posterior 의 mean, covariance 구하기</h1>

<p>이번 포스팅에서 원래 하려고했던 걸 이제야 소개한다.</p>

<p>WIP …</p>

<hr />
<h1 id="요약">요약</h1>

<hr />
<h2 id="예고">예고</h2>

<hr />
<h2 id="생각해보기">생각해보기</h2>

<hr />
<h3 id="주석">주석</h3>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:likelihood" role="doc-endnote">
      <p><a href="https://dtransposed.github.io/blog/Bayesian-Linear-Regression.html" target="_blank"> 이 블로그 </a>의 gif 예제를 보면 이해하기 쉽다. <a href="https://dtransposed.github.io/assets/9/batch_1/Data_Space.gif" target="_blank"> data point들이 sequentially 들어올 때 </a>, 그때그때마다의 measurement에만 최대로 fit하는 예측을 내리게 된다면 <a href="https://dtransposed.github.io/assets/9/batch_1/Likelihood.gif" target="_blank"> 이렇게 들쭉날쭉한 결과를 얻게 될 것이다. </a> <a href="#fnref:likelihood" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:alpha" role="doc-endnote">
      <p>Factor graph-based SLAM 에서는 Gaussian noise 를 가정할 경우 Probability의 사뭇 추상적이었던 수식이 Least-square optimization 으로 과 동치가 되고, 문제를 iterative optimization으로 풀 수 있다는 장점이 있기도 하다. <a href="https://link.springer.com/article/10.1023/A:1008854305733"> Lu and Milios 의 1997년 논문</a> 이 optimization-based SLAM의 시초로 평가받는 듯하다. (하지만 이에 대해서 입문용으로는 Square Root SAM 논문이 제일 정석적이고 좋은 듯) <a href="#fnref:alpha" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:conju" role="doc-endnote">
      <p>우리는 지금 posterior 가 prior 와 같은 분포 패밀리가 되는 것을 원하고 있었다. Gaussian = Gaussian $\times$ Gaussian 인 조합 외에, conjugate distribution이라고 검색해보면 몇개 더 다양한 분포의 조합이 가능함을 알 수 있다. 하지만 practically, Gaussian 말고 별로 다른 조합은 적어도 SLAM에서는 잘 써본 적이 없다 (== Gaussian에 대해서만 일단 잘 알면 된다). <a href="#fnref:conju" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:cov" role="doc-endnote">
      <p>또한, covariance 는 uncertainty 의 의미로써 그 자체로도 solely 다양한 application에 활용 될 수 있다. 예를 들어 loop closing 을 수행하기 위해 어느 정도 반경 내의 후보 node 들만 검색하는 등 search space 를 줄여줄 수 있다. <a href="#fnref:cov" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

</div>

<br>
<hr class="solid" style="margin-top:+30px">
<div id="related" style="margin-top:-20px">
  <h3>Other posts</h3>
  <ul class="posts" style="margin-top:-15px">
    
    <li>
      <!--  -->
      <span>04 Mar 2021 &raquo;</span> 
      <span style="color:gray"> [Factor graph-based SLAM] &raquo;</span>
      <a href="/blog/2021/03/04/slambackend-1.html">SLAM back-end 이야기 (1편): SLAM은 Ax=b 를 푸는 것이다</a>
      <!--  -->
    </li>
    
    <li>
      <!--  -->
      <span>02 Mar 2021 &raquo;</span> 
      <span style="color:gray"> [Factor graph-based SLAM] &raquo;</span>
      <a href="/blog/2021/03/02/slam-root.html">SLAM의 뿌리를 찾아서</a>
      <!--  -->
    </li>
    
    <li>
      <!--  -->
      <span>02 Mar 2021 &raquo;</span> 
      <span style="color:gray"> [Daily Research] &raquo;</span>
      <a href="/blog/2021/03/02/segmap-build.html">SegMap 빌드하기</a>
      <!--  -->
    </li>
    
    <li>
      <!--  -->
      <span>01 Mar 2021 &raquo;</span> 
      <span style="color:gray"> [Life] &raquo;</span>
      <a href="/blog/2021/03/01/blog-start.html">블로그 시작!</a>
      <!--  -->
    </li>
    
    <li>
      <!--  -->
    </li>
    
    <li>
      <!--  -->
    </li>
    
    <li>
      <!--  -->
    </li>
    
    <li>
      <!--  -->
    </li>
    
  </ul>
</div>


      <div class="footer">
        <div class="disclaimer" style="margin-top:+5px">

  <a title="home" style="float:right" href="/">
    Home <i class="fa fa-home"></i> 
  </a>

  <a title="top" style="float:left" href="#top">
    Top <i class="fa fa-arrow-up"></i> 
  </a>

  <br>

  <!-- 
  <p>
    The postings on this site are my own and don't necessarily represent my 
    employer’s positions, strategies or opinions.
  </p>
   -->
  
  <p>
    © <a href="http://bit.ly/gk_profile"> Giseop Kim </a>, 2021 &mdash; built with <a href="http://jekyllrb.com/">Jekyll</a> using <a href="https://github.com/swanson/lagom">Lagom theme</a>
  </p>
</div>
      </div>

    </div>
  </div>

<!-- 
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-xxxx-x']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
 -->

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-4VNTPFW7FW"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-4VNTPFW7FW');
</script>

</body>
</html>
